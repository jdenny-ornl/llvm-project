//=- KernelInfo.h - Kernel Analysis -------------------------------*- C++ -*-=//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//
//
// This file defines the KernelInfo, KernelInfoAnalysis, and KernelInfoPrinter
// classes used to extract function properties from a GPU kernel.
//
// To analyze specified LLVM IR, perhaps previously generated by something like
// 'clang -save-temps -g -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda test.c':
//
//   $ opt -disable-output test-openmp-nvptx64-nvidia-cuda.bc \
//       -load-pass-plugin=$LLVM_DIR/lib/KernelInfo.so \
//       -pass-remarks=kernel-info -passes=kernel-info
//
// To analyze specified LLVM IR it is late in a specified LLVM pass pipeline:
//
//   $ opt -disable-output test-openmp-nvptx64-nvidia-cuda.bc \
//       -load-pass-plugin=$LLVM_DIR/lib/KernelInfo.so \
//       -pass-remarks=kernel-info -passes='default<O2>'
//
// To analyze a C program as it is late in Clang's middle end:
//
//   $ clang -O2 -g -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda test.c \
//       -fpass-plugin=$LLVM_DIR/lib/KernelInfo.so -Rpass=kernel-info
//
// To analyze a C program as it is late in the linker when compiling with Clang:
//
//   $ clang -O2 -g -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda test.c \
//       -foffload-lto \
//       -Xlinker -offload-opt=-load-pass-plugin=$LLVM_DIR/lib/KernelInfo.so \
//       -Xlinker -offload-opt=-pass-remarks=kernel-info \
//       -Xlinker -offload-opt=-passes='default<O2>,function(kernel-info)'
//
// When this plugin is loaded, getKernelInfoPluginInfo in KernelInfo.cpp
// automatically inserts it late into any LLVM middle end pass pipeline, as in
// the second and third examples above.  This behavior is most helpful when
// trying to run KernelInfoAnalysis using Clang, which, unlike opt, seems to
// have no way to run a single LLVM pass by itself in the middle end.  However,
// to see results after as many optimizations as possible, it might be
// preferable to run this pass at link time, as in the last example above.
//
// How to load the plugin depends on the cmake variable
// LLVM_KERNELINFO_LINK_INTO_TOOLS, as defined by add_llvm_pass_plugin in
// ./CMakeLists.txt:
//
// - If set to On, then this plugin pass is linked statically, so it's always
//   loaded, whether using clang or opt.
// - Otherwise, this pass is a dynamically linked plugin, and something like
//   "opt -load-pass-plugin" or "clang -fpass-plugin" must be used to load it,
//   as in the above examples.
//
// opt, clang, etc. from forks of LLVM can sometimes successfully load and use
// this plugin even when this plugin is built as part of upstream LLVM sources.
// However, if a fork has diverged, the plugin might crash or otherwise
// misbehave.  Also, some clang forks have been known to produce altered debug
// metadata that this plugin cannot interpret and thus must ignore, limiting
// the info in the remarks it produces.
// ===---------------------------------------------------------------------===//

#ifndef LLVM_ANALYSIS_KERNELINFO_H
#define LLVM_ANALYSIS_KERNELINFO_H

#include "llvm/Analysis/OptimizationRemarkEmitter.h"

namespace llvm {
class DominatorTree;
class Function;

/// Data structure holding function info for kernels.
class KernelInfo {
  void updateForBB(const BasicBlock &BB, int64_t Direction,
                   OptimizationRemarkEmitter &ORE);

public:
  static KernelInfo getKernelInfo(Function &F, FunctionAnalysisManager &FAM);

  bool operator==(const KernelInfo &FPI) const {
    return std::memcmp(this, &FPI, sizeof(KernelInfo)) == 0;
  }

  bool operator!=(const KernelInfo &FPI) const { return !(*this == FPI); }

  /// If false, nothing was recorded here because the supplied function didn't
  /// appear in a module compiled for a GPU.
  bool IsValid = false;

  /// Whether the function has external linkage and is not a kernel function.
  bool ExternalNotKernel = false;

  /// OpenMP Launch bounds.
  ///@{
  std::optional<int64_t> OmpTargetNumTeams;
  std::optional<int64_t> OmpTargetThreadLimit;
  ///@}

  /// AMDGPU launch bounds.
  ///@{
  std::optional<int64_t> AmdgpuMaxNumWorkgroupsX;
  std::optional<int64_t> AmdgpuMaxNumWorkgroupsY;
  std::optional<int64_t> AmdgpuMaxNumWorkgroupsZ;
  std::optional<int64_t> AmdgpuFlatWorkGroupSizeMin;
  std::optional<int64_t> AmdgpuFlatWorkGroupSizeMax;
  std::optional<int64_t> AmdgpuWavesPerEuMin;
  std::optional<int64_t> AmdgpuWavesPerEuMax;
  ///@}

  /// NVPTX launch bounds.
  ///@{
  std::optional<int64_t> Maxclusterrank;
  std::optional<int64_t> Maxntidx;
  ///@}

  /// The number of alloca instructions inside the function, the number of those
  /// with allocation sizes that cannot be determined at compile time, and the
  /// sum of the sizes that can be.
  ///
  /// With the current implementation for at least some GPU archs,
  /// AllocasDyn > 0 might not be possible, but we report AllocasDyn anyway in
  /// case the implementation changes.
  int64_t Allocas = 0;
  int64_t AllocasDyn = 0;
  int64_t AllocasStaticSizeSum = 0;

  /// Number of direct/indirect calls (anything derived from CallBase).
  int64_t DirectCalls = 0;
  int64_t IndirectCalls = 0;

  /// Number of direct calls made from this function to other functions
  /// defined in this module.
  int64_t DirectCallsToDefinedFunctions = 0;

  /// Number of calls of type InvokeInst.
  int64_t Invokes = 0;
};

/// Analysis class for KernelInfo.
class KernelInfoAnalysis : public AnalysisInfoMixin<KernelInfoAnalysis> {
public:
  static AnalysisKey Key;

  using Result = const KernelInfo;

  KernelInfo run(Function &F, FunctionAnalysisManager &FAM) {
    return KernelInfo::getKernelInfo(F, FAM);
  }
};

/// Printer pass for KernelInfoAnalysis.
///
/// It just calls KernelInfoAnalysis, which prints remarks if they are enabled.
class KernelInfoPrinter : public PassInfoMixin<KernelInfoPrinter> {
public:
  explicit KernelInfoPrinter() {}

  PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM) {
    AM.getResult<KernelInfoAnalysis>(F);
    return PreservedAnalyses::all();
  }

  static bool isRequired() { return true; }
};
} // namespace llvm
#endif // LLVM_ANALYSIS_KERNELINFO_H
